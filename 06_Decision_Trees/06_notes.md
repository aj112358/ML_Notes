# Ch 6 - Decision Trees

## Chapter Objectives

1. Learn how to visualize a decision tree once trained
    1. Will need the 'graphviz' library installed!
2. Learn how a decision tree makes predictions
    1. For classification tasks
    2. For regression tasks
3. Learn about impurity of a node
    1. Gini impurity metric
4. Learn how a decision tree estimates class probabilities
5. Learn and implement SKL's CART training algorithm for decision trees
6. Compare and contrast the Gini impurity and entropy metrics
7. Learn how to implement regularization





## 6.1 - Training and Visualizing a Decision Tree
## 6.2 - Making Predictions
## 6.3 - Estimating Class Probabilities
## 6.4 - The CART Training Algorithm
## 6.5 - Computational Complexity
## 6.6 - Gini Impurity or Entropy?
## 6.7 - Regularization Hyperparameters
## 6.8 - Regression
## 6.9 - Instability

## - Concluding Remarks




[anomaly_detection]: https://github.com/aj112358/ML_Notes/blob/main/01_The_Machine_Learning_Landscape/01_images/anomaly_detection.png "illustration of anomaly detection"
